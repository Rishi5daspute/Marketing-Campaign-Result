# Situation

Freedom launched a $5M marketing campaign to communicate the value of its debt-relief program and motivate customers to take meaningful steps toward financial freedom.
The campaign ran for one month (Month 3) within a five-month observation period.

Post-campaign, stakeholders wanted clarity on:

Whether the campaign led to real financial impact, not just awareness

Which customer segments responded the most

Whether campaign timing influenced outcomes

The challenge was to isolate campaign-driven behavior from normal customer activity and present insights in a way that could support future strategic decisions.

# Task

The objective of this analysis was to:

Quantify the true business impact of the campaign

Use metrics that directly reflect revenue-relevant behavior

Identify high-value customer segments that drove results

Provide clear recommendations for future campaigns

Evaluate whether running the campaign in Month 3 was the right timing decision

All findings needed to be clear, conservative, and explainable to non-technical stakeholders.

# Action
1. Understanding the customer base before measuring impact

<img width="580" height="455" alt="client age distribution" src="https://github.com/user-attachments/assets/48960186-72c0-48bf-989f-f21f5deac7b0" />


Before evaluating campaign performance, I analyzed the customer demographic profile to ensure the audience was stable and financially capable.

What this revealed:
The customer base is primarily concentrated between ages 40–65, indicating financial maturity and consistency across the dataset.

Why this mattered:
This ensured that later changes in behavior could be confidently attributed to the campaign rather than demographic volatility.

2. Selecting a success metric aligned with real business value

<img width="833" height="624" alt="deposit amount by type" src="https://github.com/user-attachments/assets/77ff5df6-b902-426c-ad62-b384f8ba593a" />


To avoid overstating performance, I distinguished between:

Actual deposits (money transferred)

Scheduled deposits (planned but not yet realized)

Only actual deposits were used in campaign evaluation.

Why this mattered:
This ensured the analysis reflected real financial commitment, creating credibility across marketing, finance, and leadership teams.

3. Establishing a baseline and measuring campaign lift

<img width="846" height="624" alt="Actual deposit per month" src="https://github.com/user-attachments/assets/c07b2beb-1466-46ab-9a8b-dba3137d573b" />


I compared deposit behavior across:

Pre-campaign baseline (Months 1–2)

Campaign month (Month 3)

Post-campaign period (Months 4–5)

What this showed:
There is a clear and significant jump in deposits during Month 3, well above baseline levels.

Why this mattered:
This visually confirmed that the campaign coincided with a meaningful change in customer behavior.

4. Validating that the impact was sustained, not temporary

<img width="846" height="624" alt="Actual deposit per month" src="https://github.com/user-attachments/assets/55a88d5d-7f04-4a99-a139-6ed0b185c9ce" />


After filtering for actual deposits only, I examined whether performance remained elevated beyond the campaign month.

What this showed:
Deposits remained consistently higher in Months 4 and 5 compared to the pre-campaign baseline.

Insight:
The campaign created momentum, not just a short-term spike.

5. Confirming engagement came from more customers, not just larger transactions

[Add Graph 5: Number of Deposits per Month – Line Chart]
<img width="877" height="624" alt="number of deposit per month" src="https://github.com/user-attachments/assets/7e13aee0-a692-45c2-a392-934e2dfbe734" />

This graph tracks the count of deposits made each month.

What this showed:
There was a sharp increase in the number of deposits during the campaign month.

Insight:
The campaign increased participation across customers, not just spending by a few high-value individuals.

6. Identifying the most responsive and valuable customer segments

[Add Graph 6: Deposit Amount by Age Group Over Time – Multi-Line Chart]
<img width="848" height="624" alt="deposit count per month by age group" src="https://github.com/user-attachments/assets/309f4ffa-71e1-4dd9-b681-0d7a1b24d29a" />

Customers aged 40–60 showed the strongest response during the campaign, with higher and more sustained deposit activity.

[Add Graph 7: Deposit Amount by Residence Status – Own vs Rent]
<img width="989" height="690" alt="depsoit amount per month and residence status" src="https://github.com/user-attachments/assets/e09cb7ed-37fd-4ea7-a792-20008feb4271" />

Homeowners consistently deposited more and responded more strongly to the campaign than renters.

[Add Graph 8: Deposit Amount by Cadence – Monthly / Biweekly / Extra]
<img width="846" height="624" alt="deposit amount by cadence" src="https://github.com/user-attachments/assets/5ae6e6e5-b1f6-43c6-80b7-ac83b4208c36" />

“Extra” deposits — discretionary contributions beyond scheduled payments — increased notably during and after the campaign.

Why this mattered:
Extra deposits are a strong signal of trust, confidence, and long-term value.

7. Evaluating whether campaign timing was optimal
<img width="620" height="129" alt="image" src="https://github.com/user-attachments/assets/009fc197-c473-4c86-b044-dbd2e9964454" />


To test whether timing influenced results, I simulated a scenario where the campaign was delayed by three months.

What this showed:
Delaying the campaign would have resulted in lower total deposits and reduced revenue, even after accounting for normal customer behavior.

Insight:
Campaign timing itself played a strategic role in maximizing impact.

# Results


Key Outcomes

The campaign generated ~$13.7M in incremental deposits

Nearly 11,000 new customers joined during the campaign month

Deposit levels stayed elevated after the campaign ended

Customers aged 40–60 who own homes drove a disproportionate share of value

Extra (discretionary) deposits increased, signaling deeper engagement

Delaying the campaign would have resulted in a ~$1.75M reduction in deposits, translating to a meaningful revenue loss

Final Stakeholder Takeaway

This analysis demonstrates that the campaign:

Delivered real, measurable financial impact

Attracted high-value, financially stable customers

Created sustained behavioral change, not short-term activity

Was strategically well-timed
